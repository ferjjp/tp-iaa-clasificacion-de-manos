{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP IAA Reconocimiento de gestos",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjjp/tp-iaa-clasificacion-de-manos/blob/main/TP_IAA_Reconocimiento_de_gestos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar ambiente"
      ],
      "metadata": {
        "id": "ULrto-bO9KG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFeWgp837rWW"
      },
      "outputs": [],
      "source": [
        "#@title Instalar Auto-Keras \n",
        "#!pip install git+https://github.com/keras-team/keras-tuner.git\n",
        "!pip install keras-tuner --upgrade\n",
        "!pip install autokeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Librerías a usar\n",
        "%tensorflow_version 2.x\n",
        "import autokeras as ak\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from  sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"Librerías cargadas\")\n",
        "\n",
        "print(\"Setupeando TPU\")\n",
        "try:\n",
        "  tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu_resolver = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "  tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu_resolver)\n",
        "  print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "  \n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "id": "M-uT0VkL9zEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## selección de los parámetros \n",
        "\n",
        "#@markdown ### Parámetros de imágenes:\n",
        "imagen_largo = 50 #@param {type:\"integer\"}\n",
        "imagen_ancho = 50 #@param {type:\"integer\"}\n",
        "imagen_color = True #@param {type:\"boolean\"}\n",
        "imagen_usar_generadas_data_augmentation = True #@param {type:\"boolean\"}\n",
        "\n",
        "## aplicación de los parámetros elegidos\n",
        "\n",
        "# tamaño de las imágenes\n",
        "IMAGE_SHAPE = (imagen_largo, imagen_ancho, (3 if imagen_color else 1))\n",
        "\n",
        "# indica si se usan las imágenes generadas por data augmentation\n",
        "usarDA = imagen_usar_generadas_data_augmentation\n",
        "\n",
        "# define tamaño de datos de entrada \n",
        "num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n",
        "\n",
        "print (\"Tamaño Imagen: \", IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "f3cRjoTYBpZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Donde estan las imagenes?\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# directorio local en Google Drive\n",
        "path = 'gdrive/My Drive/IA_TP/Fotos/fase2_fer/' #@param {type:\"string\"}\n",
        "path_entrenamiento = '/Entrenamiento'  #@param {type:\"string\"}\n",
        "path_prueba = '/Pruebas'  #@param {type:\"string\"}\n",
        "\n",
        "imagPath_train = path + path_entrenamiento\n",
        "imagPath_test = path + path_prueba"
      ],
      "metadata": {
        "id": "MT0TdqvZMBUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title: Definicion del dataset\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "   imagPath_train,\n",
        "   validation_split=0.2,\n",
        "  #  label_mode='categorical',\n",
        "   subset=\"training\",\n",
        "   seed=123,\n",
        "   image_size=(imagen_largo, imagen_ancho),\n",
        "   batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "   imagPath_train,\n",
        "   validation_split=0.2,\n",
        "  #  label_mode='categorical',\n",
        "   subset=\"validation\",\n",
        "   seed=123,\n",
        "   image_size=(imagen_largo, imagen_ancho),\n",
        "   batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "def preprocess(ds):\n",
        "  return ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "train_ds = preprocess(train_ds) #prefetch ciertas imagenes\n",
        "val_ds = preprocess(val_ds)"
      ],
      "metadata": {
        "id": "HxXWwgVhexgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Definicion de modelo\n",
        "\n",
        "tipo_modelo_usar = \"ImageClassifier\" #@param [\"ImageClassifier\", \"Personalizado\"]\n",
        "\n",
        "cantidad_intentos_encontrar_modelo = 5 #@param {type:\"integer\"}\n",
        "if cantidad_intentos_encontrar_modelo < 1:\n",
        "  cantidad_intentos_encontrar_modelo = 1\n",
        "\n",
        "max_cant_params_modelo =  50000000#@param {type:\"integer\"}\n",
        "if max_cant_params_modelo <= 0:\n",
        "  max_cant_params_modelo = None\n",
        "\n",
        "max_epocas_entrenamiento =  300#@param {type:\"integer\"}\n",
        "if max_epocas_entrenamiento <= 0:\n",
        "  max_epocas_entrenamiento = None\n",
        "\n",
        "with strategy.scope():\n",
        "  if tipo_modelo_usar == \"ImageClassifier\":\n",
        "      # Initialize the image classifier.\n",
        "      AKmodel = ak.ImageClassifier( num_classes=len(class_names), \n",
        "                                            overwrite=True, \n",
        "                                            seed=1,\n",
        "                                            objective='val_accuracy')#,\n",
        "                                            # max_model_size=max_cant_params_modelo,\n",
        "                                            # max_trials=cantidad_intentos_encontrar_modelo)\n",
        "  else:\n",
        "      # capa de entrada\n",
        "      input_node = ak.ImageInput()\n",
        "      # capas intermedias\n",
        "      output_node = ak.ImageBlock(\n",
        "          # Only search ConvNet architectures.\n",
        "          block_type=\"vanilla\",\n",
        "          # Normalize the dataset.\n",
        "          normalize=True,\n",
        "          # Allow do data augmentation.\n",
        "          augment=True,\n",
        "      )(input_node)\n",
        "      # capa de salida\n",
        "      # \n",
        "      output_node = ak.ClassificationHead(num_classes=len(class_names))(output_node)\n",
        "      # Initialize AutoModel personalizado\n",
        "      AKmodel = ak.AutoModel(\n",
        "          inputs=input_node, outputs=output_node,          \n",
        "          overwrite=True, \n",
        "          seed=1,\n",
        "          objective='val_accuracy',\n",
        "          max_model_size=max_cant_params_modelo,\n",
        "          max_trials=cantidad_intentos_encontrar_modelo)\n",
        "\n",
        "print(\"Modelo preparado\")"
      ],
      "metadata": {
        "id": "635hSlxMjvmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Entrenar con AutoKeras\n",
        "\n",
        "# el history sólo devuelve el del último trial\n",
        "history = AKmodel.fit(train_ds,\n",
        "            epochs=max_epocas_entrenamiento,\n",
        "            verbose=1,\n",
        "            validation_data=val_ds)\n",
        "\n",
        "print(\"\\n>Entrenamiento Finalizado.\")"
      ],
      "metadata": {
        "id": "xsMamNhqlsrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Armar resumen del tuner\n",
        "print(AKmodel.tuner.results_summary())"
      ],
      "metadata": {
        "id": "WhGBUOl9GOmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluamos el modelo contra el dataset\n",
        "\n",
        "resEval = AKmodel.evaluate(test_ds)\n",
        "print(\"\\n>Evaluación del Mejor Modelo con datos de Prueba: \")\n",
        "print(\"    - Error: \", resEval[0])\n",
        "print(\"    - Exactitud: \", resEval[1]*100)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "DqWZGfHsbUwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Levantamos el dataset de test\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "   imagPath_test,\n",
        "   seed=123,\n",
        "   image_size=(imagen_largo, imagen_ancho),\n",
        "   batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_class_names = test_ds.class_names\n",
        "\n",
        "test_ds = preprocess(test_ds)"
      ],
      "metadata": {
        "id": "VfOsmcPyalTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Exportar Modelo y Re-Entrenar (opcional)\n",
        "\n",
        "reentrenar_modelo = False #@param {type:\"boolean\"}\n",
        "\n",
        "cant_epocas_reentrenamiento =  500#@param {type:\"integer\"}\n",
        "if cant_epocas_reentrenamiento <= 0:\n",
        "  cant_epocas_reentrenamiento = None\n",
        "\n",
        "\n",
        "# exporta el modelo y lo muestra\n",
        "print(\"\\n>> Mejor modelo generado: \")\n",
        "model = AKmodel.export_model()\n",
        "model.summary()\n",
        "print()\n",
        "print(\"==================================\\n\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='RNA.png', show_shapes=True, show_dtype=False,\n",
        "    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
        ")\n",
        "\n",
        "if reentrenar_modelo: \n",
        "  # realiza el re-entrenamiento del modelo\n",
        "  print(\"\\n\\n>Comienza el Re-Entrenamiento:\")\n",
        "  history = model.fit(train_ds,\n",
        "                        validation_data=val_ds,\n",
        "                        epochs=cant_epocas_reentrenamiento\n",
        "                        )\n",
        "  print(\"\\n>Re-Entrenamiento Finalizado.\")\n",
        "\n",
        "#@title Mostrar Gráficos del Entrenamiento\n",
        "plt.figure(figsize=(15,8)) \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Gráfico del Error del Entrenamiento')\n",
        "plt.ylabel('')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,8)) \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Gráfico de la Exactitud del Entrenamiento')\n",
        "plt.ylabel('')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z0BHT1bacpyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluar modelo contra test dataset\n",
        "\n",
        "test_images_normal = []\n",
        "test_images = []\n",
        "test_images_classes = []\n",
        "\n",
        "for image, label in test_ds:\n",
        "  # for displaying purposes\n",
        "  test_images_normal.append(image)\n",
        "  test_images_classes.append(label.numpy())\n",
        "\n",
        "predictions = model.predict(test_ds)\n",
        "\n",
        "test_predict = np.argmax(predictions,axis=1)\n",
        "flattened_real =[item for sublist in test_images_classes for item in sublist]\n",
        "test_real = np.array(flattened_real)\n",
        "\n",
        "test_acc = sum(1 if x == y else 0 for x, y in zip(test_predict.tolist(),test_real)) / len(test_real)                                       \n",
        "print(f'Test set accuracy: {test_acc:.0%}\\n')\n",
        "\n",
        "#----\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_mtx = tf.math.confusion_matrix(test_real, test_predict)\n",
        "\n",
        "print(\"Reporte de clasificacion\\n\")\n",
        "print(classification_report(flattened_real,test_predict))\n",
        "\n",
        "test_real_labels = list(map(lambda x: class_names[x],test_real))\n",
        "test_predict_labels = list(map(lambda x: class_names[x],test_predict.tolist()))\n",
        "\n",
        "cm = confusion_matrix(test_real_labels,test_predict_labels,labels=class_names)\n",
        "cmtx = pd.DataFrame(\n",
        "        cm, \n",
        "        index=['r:{:}'.format(x) for x in class_names], \n",
        "        columns=['p:{:}'.format(x) for x in class_names]\n",
        "      )\n",
        "print(cmtx)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"Heatmap de confusion o matriz\\n\")\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx, xticklabels=class_names, yticklabels=class_names, \n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Class')\n",
        "plt.show()\n",
        "\n",
        "print(\"Predicciones de ejemplo\")\n",
        "plt.figure(figsize=(50, 50))\n",
        "position = 0\n",
        "for batch in test_images_normal:\n",
        "  for image in batch:\n",
        "    prediction = tf.nn.softmax(predictions[position])\n",
        "    label = flattened_real[position]\n",
        "    position = position + 1\n",
        "    ax = plt.subplot(len(batch),1, position)\n",
        "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.title(\"Predicted {} with {:.2f}% confidence, and it was {}\"\n",
        "               .format(class_names[np.argmax(prediction)],100 * np.max(prediction),class_names[label]))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Q2LgT-EUdFq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fsq_P4eNCw5Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}